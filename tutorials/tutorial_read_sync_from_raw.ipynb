{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:30<00:00, 210.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from analysis_helpers import *\n",
    "\n",
    "folder = r'E:/CSHL/pita_g0/'\n",
    "apfiles,nidqfile = list_spikeglx_files(folder)\n",
    "\n",
    "# load the AP channel for each probe and extract the onsets and offsets from the binary files\n",
    "aps = []\n",
    "apmetas = []\n",
    "aponsets = []\n",
    "apoffsets = []\n",
    "\n",
    "for file in tqdm(apfiles):\n",
    "    b = load_spikeglx_binary(file)\n",
    "    aps.append(b[0])\n",
    "    apmetas.append(b[1])\n",
    "    o,f = unpack_npix_sync(b[0][:,-1])\n",
    "    # load onsets for each probe\n",
    "    aponsets.append(o)\n",
    "    apoffsets.append(f)\n",
    "# load the NIDQ channel and extract the onsets/offsets\n",
    "nidq,nidqmeta = load_spikeglx_binary(nidqfile)\n",
    "nidqonsets,nidqoffsets = unpack_npix_sync(nidq[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROBES:\n",
      "\t- imec0 has 1138 on channel 6\n",
      "\n",
      "DAQ:\n",
      "\t - has 540 on channel 0\n",
      "\t - has 1138 on channel 5\n"
     ]
    }
   ],
   "source": [
    "# Print how many onsets and offsets are in each probe\n",
    "print('\\nPROBES:')\n",
    "for i,ons in enumerate(aponsets):\n",
    "    for k in ons.keys():\n",
    "        npulses = len(ons[k])\n",
    "        print(f'\\t- imec{i} has {npulses} on channel {k}')\n",
    "# and on the daq digital channels\n",
    "print('\\nDAQ:')\n",
    "for k in nidqonsets.keys():\n",
    "    npulses = len(nidqonsets[k])\n",
    "    print(f'\\t - has {npulses} on channel {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by inspecting the outputs, we know that the sync is on channel 6 for the probe and on channel 5 for the DAQ\n",
    "apsyncchannel = 6\n",
    "nidqsyncchannel = 5\n",
    "# now lets interpolate to the first probe\n",
    "# interpolate data to the first probe \n",
    "from scipy.interpolate import interp1d\n",
    "apcorrections = []\n",
    "syncpulses = aponsets[0][apsyncchannel]/apmetas[0]['sRateHz'] # these are the pulses to interpolate to\n",
    "# there is only one probe here so these are not useful\n",
    "for pulses in aponsets:\n",
    "    apcorrections.append(interp1d(pulses[apsyncchannel],\n",
    "                                  syncpulses, fill_value='extrapolate')) # in samples\n",
    "    \n",
    "nidqcorrection = interp1d(nidqonsets[nidqsyncchannel],\n",
    "                                  syncpulses, fill_value='extrapolate') # in samples\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know we can correct for the actual experiment sync and extract the optogenetics pulse\n",
    "# the visual stimulus is in digital channel 0 (port0.0)\n",
    "visual_stimulus_sync = nidqcorrection(nidqonsets[0])\n",
    "\n",
    "# now lets read the analog channel, the nitime \n",
    "nitime = nidqcorrection(np.arange(0,len(nidq))) \n",
    "# find the onsets of the optogenetics stimulus\n",
    "thresh = 200\n",
    "# first threshold the analog signal (ideally we use a trigger signal instead of a threshold)\n",
    "thresholded_analog = (nidq[:,0]>thresh).astype(np.float32)\n",
    "# then do the difference, the onsets will be +1, the offsets will be -1\n",
    "diffed_threshold = np.hstack([0,np.diff(thresholded_analog)])\n",
    "# now find the location of the onsets and offsets\n",
    "opto_stimulus_sync = nidqcorrection(np.where(diffed_threshold>0.5)[0])\n",
    "# this will also detect cases when the input to the LED fluctuates a bit, lets filter that.\n",
    "# We could either filter the signal or use info from the visual stimulus.\n",
    "# Lets use info from the visual stimulus, we will only use pulses that occur 0.7s after the visual stim\n",
    "filtered_opto = []\n",
    "for o in visual_stimulus_sync:\n",
    "    # for each trial\n",
    "    tmp = opto_stimulus_sync[opto_stimulus_sync>o]\n",
    "    if len(tmp):\n",
    "        # if there is an opto that is smaller than the visual trial\n",
    "        if (tmp[0]-o)<1:\n",
    "            # if the first happended less than 1 ms in the visual stim include it. \n",
    "            filtered_opto.append(tmp[0])\n",
    "opto_stimulus_sync = np.array(filtered_opto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.675205325333334, 20.680526666666665)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "# lets plot how far off we were for each data stream\n",
    "\n",
    "# There is only one probe here so that is not useful\n",
    "# for iprobe,pulses in enumerate(aponsets):\n",
    "#     plt.figure(figsize=[8,3])\n",
    "#     plt.plot((syncpulses-pulses[apsyncchannel]/apmetas[iprobe]['sRateHz'])*1000,'ko',label='measured',alpha=0.5)\n",
    "#     plt.plot((syncpulses-apcorrections[iprobe](pulses[apsyncchannel]))*1000,'r.',label='corrected',alpha=0.5)\n",
    "#     plt.ylim([-5,5])\n",
    "#     plt.xlabel('time in experiment (s)')\n",
    "#     plt.ylabel('measured-corrected (ms)')\n",
    "# for here we care only about the NIDAQ\n",
    "plt.figure()\n",
    "plt.plot([syncpulses[0],syncpulses[-1]],[0,0],'-',color='lightgray')\n",
    "plt.plot((syncpulses-nidqonsets[nidqsyncchannel]/nidqmeta['sRateHz'])*1000,'k.',label='measured',alpha=0.5)\n",
    "plt.plot((syncpulses-nidqcorrection(nidqonsets[nidqsyncchannel]))*1000,'r.',label='corrected',alpha=0.5)\n",
    "plt.xlabel('time in experiment (s)')\n",
    "plt.ylabel('measured-corrected (ms)')\n",
    "plt.ylim([-2,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the syncs \n",
    "plt.figure()\n",
    "plt.plot(nitime[:1000000],nidq[:1000000,0])\n",
    "\n",
    "plt.vlines(visual_stimulus_sync[visual_stimulus_sync<nitime[1000000]],15000,20000)\n",
    "plt.vlines(opto_stimulus_sync[opto_stimulus_sync<nitime[1000000]],20000,25000,color='blue')\n",
    "\n",
    "plt.yticks([7500,18000,23000],['optogenetics pulses','visual stimuli','opto stimuli']);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the syncs\n",
    "import h5py as h5\n",
    "outputfile = pjoin(folder,'experiment_syncs.h5')\n",
    "with h5.File(outputfile,'w') as fd:\n",
    "    #save the corrected syncs, the sampling rate, and the \n",
    "    fd.create_dataset('opto_sync_s',data = opto_stimulus_sync)\n",
    "    fd.create_dataset('visual_sync_s',data = visual_stimulus_sync)\n",
    "    fd.create_dataset('stream_apsyncs',data = syncpulses)\n",
    "    fd.create_dataset('stream_nisyncs',data = nidqoffsets[nidqsyncchannel])\n",
    "    fd.create_dataset('sampling_rate',data = apmetas[0]['sRateHz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
